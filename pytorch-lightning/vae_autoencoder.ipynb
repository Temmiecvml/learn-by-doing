{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels, num_groups):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.gn1 = nn.GroupNorm(num_groups, channels)\n",
    "        self.gn2 = nn.GroupNorm(num_groups, channels)\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.gn1(x)\n",
    "        out = F.silu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.gn2(out)\n",
    "        out = F.silu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    \"\"\"Convolutional Variational Autoencoder with ResNet connections.\"\"\"\n",
    "    def __init__(self, base_channels, num_groups=8, dropout_prob=0.5):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = 128\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, base_channels, kernel_size=3, padding=1),\n",
    "            self._conv_block(base_channels, base_channels, stride=2, num_groups=num_groups),  # (256, 256) -> (128, 128)\n",
    "            ResBlock(base_channels, num_groups),\n",
    "            self._conv_block(base_channels, base_channels * 2, stride=2, num_groups=num_groups),  # (128, 128) -> (64, 64)\n",
    "            ResBlock(base_channels * 2, num_groups),\n",
    "            self._conv_block(base_channels * 2, base_channels * 4, stride=2, num_groups=num_groups),  # (64, 64) -> (32, 32)\n",
    "            ResBlock(base_channels * 4, num_groups),\n",
    "            self._conv_block(base_channels * 4, base_channels * 8, stride=2, num_groups=num_groups),  # (32, 32) -> (16, 16)\n",
    "            ResBlock(base_channels * 8, num_groups),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.flattened_dims = base_channels * 8 * 16 * 16\n",
    "        self.fc_mean = nn.Linear(self.flattened_dims, self.latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.flattened_dims, self.latent_dim)\n",
    "\n",
    "        self.decoder_input = nn.Linear(self.latent_dim, self.flattened_dims)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (base_channels * 8, 16, 16)),\n",
    "            ResBlock(base_channels * 8, num_groups),\n",
    "            self._conv_transpose_block(base_channels * 8, base_channels * 4, num_groups=num_groups),  # (16, 16) -> (32, 32)\n",
    "            ResBlock(base_channels * 4, num_groups),\n",
    "            self._conv_transpose_block(base_channels * 4, base_channels * 2, num_groups=num_groups),  # (32, 32) -> (64, 64)\n",
    "            ResBlock(base_channels * 2, num_groups),\n",
    "            self._conv_transpose_block(base_channels * 2, base_channels, num_groups=num_groups),  # (64, 64) -> (128, 128)\n",
    "            ResBlock(base_channels, num_groups),\n",
    "            self._conv_transpose_block(base_channels, base_channels // 2, num_groups=num_groups),  # (128, 128) -> (256, 256)\n",
    "            nn.GroupNorm(num_groups, base_channels // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_channels // 2, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _conv_block(self, in_channels, out_channels, stride=1, num_groups=8):\n",
    "        return nn.Sequential(\n",
    "            nn.GroupNorm(num_groups, in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Dropout(self.dropout_prob) \n",
    "            \n",
    "        )\n",
    "\n",
    "    def _conv_transpose_block(self, in_channels, out_channels, num_groups=8):\n",
    "        return nn.Sequential(\n",
    "            nn.GroupNorm(num_groups, in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Dropout(self.dropout_prob)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.fc_mean(x), self.fc_logvar(x)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_input(z)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    @staticmethod\n",
    "    def recommend_num_groups(base_channels):\n",
    "        \"\"\"Recommend the number of groups for GroupNorm based on base channels.\"\"\"\n",
    "        if base_channels < 16:\n",
    "            return 4\n",
    "        elif base_channels < 64:\n",
    "            return 8\n",
    "        elif base_channels < 256:\n",
    "            return 16\n",
    "        else:\n",
    "            return 32\n",
    "\n",
    "\n",
    "base_channels = 32  \n",
    "num_groups = CVAE.recommend_num_groups(base_channels)\n",
    "dropout_prob = 0.1 \n",
    "img_size = 256\n",
    "\n",
    "model = CVAE(base_channels, num_groups=num_groups, dropout_prob=dropout_prob)\n",
    "input_image = torch.randn(1, 3, img_size, img_size)\n",
    "output_image, mu, logvar = model(input_image)\n",
    "print(output_image.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "- **HuggingFaceDataset**: Ryan-sjtu/celebahq-caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "class CVAELightning(pl.LightningModule):\n",
    "    def __init__(self, img_size=32, latent_dim=128, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = CVAE(img_size)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        recon_x, mu, logvar = self(x)\n",
    "        loss = self.loss_function(recon_x, x, mu, logvar)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        recon_x, mu, logvar = self(x)\n",
    "        loss = self.loss_function(recon_x, x, mu, logvar)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        recon_x, mu, logvar = self(x)\n",
    "        loss = self.loss_function(recon_x, x, mu, logvar)\n",
    "        self.log('test_loss', loss)\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, min_lr=1e-6)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Download the CIFAR10 dataset\n",
    "        CIFAR10(root='./data', train=True, download=True)\n",
    "        CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Transform\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        # Load and split datasets\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_full = CIFAR10(root='./data', train=True, transform=transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=64, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=64, num_workers=4)\n",
    "\n",
    "# Example usage:\n",
    "model = CVAELightning(img_size=32, latent_dim=128)\n",
    "trainer = pl.Trainer(max_epochs=10, gpus=1 if torch.cuda.is_available() else 0)\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lbd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
